<img src="https://bit.ly/2VnXWr2" alt="Ironhack Logo" width="100"/>

# Criminality in New York City
**Rubén Martínez Lorente**

** *Data Analytics at Ironhack School in Barcelona.  20/12/2019* ** 

## Content
- [Project Description](#project-description)
- [Dataset](#dataset)
- [Cleaing](#data-cleaning)
- [Analysis](#data-analysis)
- [Workflow](#workflow)
- [Organization](#organization)
- [Links](#links)

## Project Description

The project introduced here is the penultimate project for the Bootcamp of *Data Analytics* in the school Ironhack in Barcelona. I want to apply data analysis learnt in so far in the bootcamp, such as python, pandas, ETL, reporting, etc.

Conceptually, the project is about the criminality in New York City (US). The goal of this project is the analysis of the criminality of New York City (U.S.) taking some features from the New York Police Department (NYPD, see [Dataset](#dataset)).
I want to know which the safest boro (from the five there are in the city: Brooklyn, Queens, Manhattan, Bronx and Staten Island) and the most dangeours as function of the crimes commmited, gender, ethnicity, etc.

The final report you can see in [Slides](#links). The organization of the project you can see in [Organization](#organization), where you can find the jupyter notebook file where is the code, as weel as the images and the .csv files (raw and cleaned). 

## Dataset

I use a single dataset from kaggle website. We have information about date and places of crimes, and which kind of criminality according with usual and internal (NYPD codes). 

**Dataset**: *https://www.kaggle.com/adamschroeder/crime-in-new-york-city/data*

            *https://data.cityofnewyork.us/Public-Safety/NYPD-Arrest-Data-Year-to-Date-/uip8-fykc*

## Data Cleaning

## Data Analysis

## Workflow
Outline the workflow you used in your project. What are the steps you went through?

## Organization
The project folder in Github [Repository] is organized in the following mode:

* jupyter_notebook: the .ipynb file where data is cleaned and analyzed.
    - 1.data_cleaning.ipynb
    - 2.data_analyzing.ipynb

* images: there are the images used the final report.

* raw_data: the raw .csv files used to make the ETL.

* clean_data: .csv files cleaned and ready to analyze.

And the following file:

- README.md


## Links
Here are the links related to the project, where you may find all files need to understand the project.

[Repository](https://github.com/rubenmartinezlorente/Project-Week-5-Your-Own-Project.git)  


[Slides](https://docs.google.com/presentation/d/16bp7NePZfApK6wA6oZ76HFyrGCHZ0lw3fL86h_5VKDU/edit?folder=1HB9m3JqtlN_VEYlb5wIypphppu3RmjRb#slide=id.g6baef779aa_0_19)  